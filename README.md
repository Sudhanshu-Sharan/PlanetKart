
<artifacts>
<artifact identifier="clean_readme" type="text/markdown" title="Clean PlanetKart Analytics README">

# ğŸŒŒ PlanetKart Analytics
Modern Data Engineering Platform for Multi-Planetary E-commerce
A complete analytics platform built with dbt and Snowflake, transforming raw e-commerce data into actionable business intelligence using industry best practices.

## ğŸ¯ What This Project Demonstrates

- **Star Schema Design** with optimized fact and dimension tables
- **4-Layer Architecture** (Raw â†’ Staging â†’ Marts â†’ Analysis) for data quality
- **25+ Automated Tests** ensuring reliability and business rule validation
- **Type 2 SCD** for historical change tracking
- **Production-Ready** with comprehensive documentation and testing

## ğŸ—ï¸ Data Architecture

### Data Flow Pipeline
```
ğŸ“¥ Source Files â†’ â„ï¸ Snowflake Raw â†’ ğŸ§¹ Staging â†’ ğŸ¯ Marts â†’ ğŸ“ˆ Analysis
     â†“              â†“                â†“           â†“         â†“
  CSV Files    PLANETKART_RAW    5 Views    Star Schema  4 Views
```

### Detailed Architecture
```
â”Œâ”€ Raw Data Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“„ customers.csv    â†’ ğŸ‘¥ customers      â”‚
â”‚  ğŸ“„ orders.csv       â†’ ğŸ“¦ orders         â”‚
â”‚  ğŸ“„ order_items.csv  â†’ ğŸ›’ order_items    â”‚
â”‚  ğŸ“„ products.csv     â†’ ğŸ“¦ products       â”‚
â”‚  ğŸ“„ regions.csv      â†’ ğŸŒ regions        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€ Staging Layer (Views) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ‘¥ stg_customers    (data cleaning)    â”‚
â”‚  ğŸ“¦ stg_orders       (standardization)  â”‚
â”‚  ğŸ›’ stg_order_items  (calculations)     â”‚
â”‚  ğŸ“¦ stg_products     (validation)       â”‚
â”‚  ğŸŒ stg_regions      (formatting)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€ Marts Layer (Tables) - Star Schema â”€â”€â”€â”€â”
â”‚           ğŸ“Š fact_orders                â”‚
â”‚              â†—    â†‘    â†–               â”‚
â”‚  ğŸ‘¥ dim_customers  ğŸ“¦ dim_products      â”‚
â”‚              â†˜           â†™              â”‚
â”‚            ğŸŒ dim_regions               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€ Analysis Layer (Views) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š business_kpis     (executive KPIs)  â”‚
â”‚  ğŸ‘¥ customer_insights (segmentation)    â”‚
â”‚  ğŸ“¦ product_insights  (profitability)   â”‚
â”‚  ğŸŒ regional_insights (market analysis) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€ Snapshots (Type 2 SCD) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¸ snap_customers (change tracking)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## â­ Star Schema Design

```
                    ğŸ“Š FACT_ORDERS
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ â€¢ order_sk (PK) â”‚
ğŸ‘¥ DIM_CUSTOMERS   â”‚ â€¢ customer_sk   â”‚   ğŸ“¦ DIM_PRODUCTS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â€¢ region_sk     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ customer_sk  â”‚â—„â”€â”€â”¤ â€¢ order_revenue â”‚â”€â”€â–ºâ”‚ product_sk   â”‚
â”‚ customer_nameâ”‚   â”‚ â€¢ order_profit  â”‚   â”‚ product_name â”‚
â”‚ revenue_seg  â”‚   â”‚ â€¢ total_quantityâ”‚   â”‚ category     â”‚
â”‚ lifecycle    â”‚   â”‚ â€¢ profit_tier   â”‚   â”‚ profit_seg   â”‚
â”‚ churn_risk   â”‚   â”‚ â€¢ is_completed  â”‚   â”‚ sales_perf   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   ğŸŒ DIM_REGIONS
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ region_sk    â”‚
                   â”‚ planet       â”‚
                   â”‚ zone         â”‚
                   â”‚ market_cat   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ How to Run and Test the Project

### Prerequisites
```bash
# Required tools
- Python 3.8+
- dbt-core with Snowflake adapter
- Snowflake account with ACCOUNTADMIN privileges
- VS Code (recommended)
```

### Step 1: Environment Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/planetkart-analytics.git
cd planetkart-analytics

# Create virtual environment
python -m venv venv

# Activate virtual environment
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Step 2: dbt Configuration
```bash
# Install dbt packages
dbt deps

# Test connection to Snowflake
dbt debug
```
*Should show "All checks passed!" if connection is successful*

### Step 3: Build the Complete Pipeline
```bash
# Build all models in correct order
dbt run

# Expected output: 13 models built successfully
# - 5 staging views
# - 4 marts tables  
# - 4 analysis views
```

### Step 4: Create Type 2 SCD Snapshot
```bash
# Create customer snapshot for change tracking
dbt snapshot

# Verify snapshot created
dbt ls -s snapshots
```

### Step 5: Run Data Quality Tests
```bash
# Execute all 25+ data quality tests
dbt test

# Expected: All tests should pass
# Tests cover: unique keys, not null values, accepted values, relationships
```

### Step 6: Generate Documentation
```bash
# Generate project documentation with lineage
dbt docs generate

# Serve documentation locally (optional)
dbt docs serve
# Opens at http://localhost:8080
```

### Execute Project Commands
```bash
# Build all models
dbt run

# Run by layer
dbt run --select staging          # Clean data (5 views)
dbt run --select marts            # Star schema (4 tables)
dbt run --select Advance_analysis # Business insights (4 views)

# Quality assurance
dbt test                          # 25+ automated tests
dbt snapshot                      # Historical tracking

# Documentation
dbt docs generate && dbt docs serve
```

## ğŸ“Š Business Value

**Customer Intelligence**: Revenue segmentation, lifecycle analysis, churn risk identification  
**Product Analytics**: Profitability analysis, category performance, inventory optimization  
**Regional Strategy**: Multi-planetary market analysis for expansion planning  
**Executive Reporting**: Real-time KPIs for strategic decision making

## ğŸ”§ Key Design Decisions

**Star Schema**: Chosen for query performance and business user intuition  
**Materialization**: Views for staging/analysis (fresh data), tables for marts (performance)  
**Surrogate Keys**: Integer-based keys using `dbt_utils` for scalability  
**Testing**: Comprehensive validation covering uniqueness, business rules, and data freshness

## ğŸ§ª Data Quality Framework

| Test Category | Count | Purpose |
|---------------|-------|---------|
| **Uniqueness** | 8 tests | Ensure primary key integrity |
| **Not Null** | 10 tests | Validate required fields |
| **Relationships** | 4 tests | Check referential integrity |
| **Accepted Values** | 3 tests | Validate business rules |
| **Custom Logic** | 2 tests | Revenue/profit calculations |

### Data Quality Features
- **25+ Automated Tests**: Uniqueness, referential integrity, business rules
- **Source Freshness**: Monitoring data recency with configurable alerts
- **Type 2 SCD**: Historical tracking of customer profile changes
- **Custom Validations**: Revenue calculations and profit logic verification

## ğŸ“ Project Structure

```
planetkart-analytics/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/              # Data cleaning (5 views)
â”‚   â”‚   â”œâ”€â”€ _sources.yml      # Source definitions & freshness tests
â”‚   â”‚   â”œâ”€â”€ stg_customers.sql # Customer data standardization
â”‚   â”‚   â”œâ”€â”€ stg_orders.sql    # Order data cleaning
â”‚   â”‚   â”œâ”€â”€ stg_order_items.sql # Line item calculations
â”‚   â”‚   â”œâ”€â”€ stg_products.sql  # Product catalog cleaning
â”‚   â”‚   â””â”€â”€ stg_regions.sql   # Geographic standardization
â”‚   â”œâ”€â”€ marts/                # Star schema (4 tables)
â”‚   â”‚   â”œâ”€â”€ schema.yml        # Model tests & documentation
â”‚   â”‚   â”œâ”€â”€ dim_customers.sql # Customer dimension with segmentation
â”‚   â”‚   â”œâ”€â”€ dim_products.sql  # Product dimension with profitability
â”‚   â”‚   â”œâ”€â”€ dim_regions.sql   # Regional dimension with categories
â”‚   â”‚   â””â”€â”€ fact_orders.sql   # Central fact table with metrics
â”‚   â””â”€â”€ Advance_analysis/     # Business insights (4 views)
â”‚       â”œâ”€â”€ customer_insights.sql # Customer segment analysis
â”‚       â”œâ”€â”€ product_insights.sql  # Product performance metrics
â”‚       â”œâ”€â”€ regional_insights.sql # Regional intelligence
â”‚       â””â”€â”€ business_kpis.sql     # Executive dashboard
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ snap_customers.sql    # Type 2 SCD for change tracking
â”œâ”€â”€ macros/
â”‚   â””â”€â”€ get_custom_schema.sql # Schema naming logic
â”œâ”€â”€ tests/                    # Custom data validations
â”œâ”€â”€ dbt_project.yml          # Project configuration
â”œâ”€â”€ packages.yml             # Dependencies (dbt_utils)
â””â”€â”€ requirements.txt         # Python dependencies
```

## Screenshots 

**Dbt DAG Ref** : 

<img width="1346" height="804" alt="image" src="https://github.com/user-attachments/assets/b5ee1f32-218c-479b-9250-7b4d33644766" />

**Airbyte Initial Setup** : 

<img width="512" height="320" alt="Airbyte Initial setup " src="https://github.com/user-attachments/assets/ecff848a-9f07-40ac-9f01-2dfae54e9b29" />

**Airbyte Data Moving**:

<img width="512" height="320" alt="image" src="https://github.com/user-attachments/assets/c9379ed5-81ea-446b-9092-85ddc2f4ec4a" />

**Snowflake Data**:

<img width="2044" height="1184" alt="image" src="https://github.com/user-attachments/assets/045e37fe-6161-445f-8240-bd3d8eddf39a" />

<img width="1094" height="733" alt="image" src="https://github.com/user-attachments/assets/701dc7a7-4882-4f05-acf9-76c4cf78d370" />

**Dashobard In Progress**: 

<img width="727" height="599" alt="Screenshot 2025-07-21 at 11 01 29â€¯PM" src="https://github.com/user-attachments/assets/e62ca056-100e-4daa-8ae8-ef895d6f2ccc" />


## ğŸ“ˆ Sample Analytics

**Customer Segmentation**:
- High Value: $150+ revenue (Premium retention focus)
- Medium Value: $80-149 (Growth opportunities)  
- Low Value: $1-79 (Activation campaigns)

**Product Performance**:
- Galactic Blender: $205 revenue, 61% profit margin
- Solar Charger: $89 revenue, 28% profit margin
- Categories ranked by profitability for inventory decisions

**Regional Analysis**:
- Earth (Home Base): 60% of revenue
- Mars (Expansion): 25% of revenue, highest growth
- Venus (Territory): 15% of revenue, emerging market

## ğŸ¯ Project Metrics

- **17 Models**: 5 staging + 4 marts + 4 analysis + 4 snapshots
- **5 Schemas**: Organized data flow across Raw â†’ Stage â†’ Analytics â†’ Snapshots
- **100% Test Coverage**: All critical business logic validated
- **Star Schema**: 1 fact table + 3 dimension tables optimized for analytics

---

**Tech Stack**: dbt â€¢ Snowflake â€¢ SQL â€¢ Python â€¢ Git  
**Contact**: [LinkedIn](https://linkedin.com/in/sudhanshu-sharan) | [Email](mailto:s.sharan5454@gmail.com)
</artifact>
</artifacts>
